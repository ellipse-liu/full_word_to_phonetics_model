{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7494afbc-68f2-494c-b3a9-cb8acc5e7644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Concatenate, Bidirectional\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from BahdanauAttention import AttentionLayer\n",
    "import numpy as np\n",
    "import random\n",
    "import eng_to_ipa as ipa\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eab04bf-9125-43fe-9f01-0df8a30bfd23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class bi_model:\n",
    "    def __init__(self, max_encoder_len, max_decoder_len, build_inference_model_encoder_vocab, num_decoder_vocab):\n",
    "        self.latent_dim = 256\n",
    "        self.embedding_dim = 200\n",
    "        self.max_encoder_len = max_encoder_len\n",
    "        self.max_decoder_len = max_decoder_len\n",
    "        self.num_encoder_vocab = num_encoder_vocab\n",
    "        self.num_decoder_vocab = num_decoder_vocab\n",
    "        self.encoder_model_inference = None\n",
    "        self.decoder_model_inference = None\n",
    "\n",
    "        self.build_encoder()\n",
    "        self.build_decoder()\n",
    "        self.training_model = Model([self.encoder_inputs, self.decoder_inputs], self.decoder_outputs) \n",
    "        \n",
    "    def build_encoder(self):\n",
    "        self.encoder_inputs = Input(shape=(self.max_encoder_len,)) \n",
    "        # Embedding layer- i am using 1024 output-dim for embedding you can try diff values 100,256,512,1000\n",
    "        self.enc_emb = Embedding(self.num_encoder_vocab, self.embedding_dim, trainable = True)(self.encoder_inputs)\n",
    "\n",
    "        # Bidirectional lstm layer\n",
    "        self.enc_lstm1 = Bidirectional(LSTM(self.latent_dim,return_sequences=True,return_state=True))\n",
    "        self.encoder_outputs1, self.forw_state_h, self.forw_state_c, self.back_state_h, self.back_state_c = self.enc_lstm1(self.enc_emb)\n",
    "\n",
    "        # Concatenate both h and c \n",
    "        self.final_enc_h = Concatenate()([self.forw_state_h,self.back_state_h])\n",
    "        self.final_enc_c = Concatenate()([self.forw_state_c,self.back_state_c])\n",
    "\n",
    "        # get Context vector\n",
    "        self.encoder_states =[self.final_enc_h, self.final_enc_c]\n",
    "    def build_decoder(self):\n",
    "        self.decoder_inputs = Input(shape=(None,)) \n",
    "\n",
    "        # decoder embedding with same number as encoder embedding\n",
    "        self.dec_emb_layer = Embedding(self.num_decoder_vocab, self.embedding_dim) \n",
    "        self.dec_emb = self.dec_emb_layer(self.decoder_inputs)   # apply this way because we need embedding layer for prediction \n",
    "\n",
    "        # In encoder we used Bidirectional so it's having two LSTM's so we have to take double units(256*2=512) for single decoder lstm\n",
    "        # LSTM using encoder's final states as initial state\n",
    "        self.decoder_lstm = LSTM(self.latent_dim*2, return_sequences=True, return_state=True) \n",
    "        self.decoder_outputs, _, _ = self.decoder_lstm(self.dec_emb, initial_state=self.encoder_states)\n",
    "\n",
    "        # Using Attention Layer\n",
    "        self.attention_layer = AttentionLayer()\n",
    "        self.attention_result, self.attention_weights = self.attention_layer([self.encoder_outputs1, self.decoder_outputs])\n",
    "\n",
    "        # Concat attention output and decoder LSTM output \n",
    "        self.decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([self.decoder_outputs, self.attention_result])\n",
    "\n",
    "        # Dense layer with softmax\n",
    "        self.decoder_dense = Dense(self.num_decoder_vocab, activation='softmax')\n",
    "        self.decoder_outputs = self.decoder_dense(self.decoder_concat_input)\n",
    "        \n",
    "    def compile(self):\n",
    "        self.training_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics = ['acc'])\n",
    "    \n",
    "    def fit(self, x_tr, y_tr_in, y_tr_out, x_test, y_test_in, y_test_out, ep, batch_size):\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "        ck = ModelCheckpoint(filepath='segmenter_best_weights.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "        Callbacks = [es, ck]\n",
    "        self.training_model.fit([x_tr,y_tr_in], y_tr_out, epochs = ep, callbacks=Callbacks, batch_size = batch_size, validation_data=(([x_test,y_test_in]), y_test_out))\n",
    "\n",
    "    def build_inference_model(self):\n",
    "        self.encoder_model_inference = Model(self.encoder_inputs, outputs = [self.encoder_outputs1, self.final_enc_h, self.final_enc_c])\n",
    "        self.encoder_model_inference.save('final_encoder_model_segmenter.h5')\n",
    "\n",
    "        # Decoder Inference\n",
    "        self.decoder_state_h = Input(shape=(self.latent_dim*2,)) # This numbers has to be same as units of lstm's on which model is trained\n",
    "        self.decoder_state_c = Input(shape=(self.latent_dim*2,))\n",
    "\n",
    "        # we need hidden state for attention layer\n",
    "        # 36 is maximum length if english sentence It has to same as input taken by attention layer can see in model plot\n",
    "        self.decoder_hidden_state_input = Input(shape=(self.max_encoder_len,self.latent_dim*2)) \n",
    "        # get decoder states\n",
    "        self.dec_states = [self.decoder_state_h, self.decoder_state_c]\n",
    "\n",
    "        # embedding layer \n",
    "        self.dec_emb2 = self.dec_emb_layer(self.decoder_inputs)\n",
    "        self.decoder_outputs2, self.state_h2, self.state_c2 = self.decoder_lstm(self.dec_emb2, initial_state=self.dec_states)\n",
    "\n",
    "        # Attention inference\n",
    "        self.attention_result_inf, self.attention_weights_inf = self.attention_layer([self.decoder_hidden_state_input, self.decoder_outputs2])\n",
    "        self.decoder_concat_input_inf = Concatenate(axis=-1, name='concat_layer')([self.decoder_outputs2, self.attention_result_inf])\n",
    "\n",
    "        self.dec_states2= [self.state_h2, self.state_c2]\n",
    "        self.decoder_outputs2 = self.decoder_dense(self.decoder_concat_input_inf)\n",
    "\n",
    "        # get decoder model\n",
    "        self.decoder_model_inference= Model(\n",
    "                            [self.decoder_inputs] + [self.decoder_hidden_state_input, self.decoder_state_h, self.decoder_state_c],\n",
    "                             [self.decoder_outputs2]+ self.dec_states2)\n",
    "        self.decoder_model_inference.save('final_decoder_model_segmenter.h5')\n",
    "        \n",
    "    def decode_sequence(self, input_seq, i2o, o2i):\n",
    "        e_out ,e_h, e_c = self.encoder_model_inference.predict(input_seq, verbose = 0)\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = o2i['<']\n",
    "\n",
    "        stop_condition = False\n",
    "        decoded_sentence = []\n",
    "\n",
    "        while not stop_condition:\n",
    "            (output_tokens, h, c) = self.decoder_model_inference.predict([target_seq] + [e_out, e_h, e_c], verbose = 0)\n",
    "\n",
    "            # Sample a token\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_token = i2o[sampled_token_index]   \n",
    "\n",
    "            if sampled_token != '>':\n",
    "                decoded_sentence += [sampled_token]\n",
    "\n",
    "            # Exit condition: either hit max length or find the stop word.\n",
    "            if (sampled_token == '>') or (len(decoded_sentence) >= self.max_decoder_len):\n",
    "                stop_condition = True\n",
    "\n",
    "            # Update the target sequence (of length 1)\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "            # Update internal states\n",
    "            (e_h, e_c) = (h, c)\n",
    "        return decoded_sentence\n",
    "    def word2seq(self, a2i, input_word):\n",
    "        final_seq = []\n",
    "        for c in input_word:\n",
    "            final_seq += [a2i[c]]\n",
    "        final_seq = pad_sequences([final_seq], maxlen=self.max_encoder_len, padding='post')[0]\n",
    "        return final_seq\n",
    "    \n",
    "    def translate(self, input_word, a2i, i2o, o2i):\n",
    "        seq = self.word2seq(a2i, input_word).reshape(1, self.max_encoder_len)\n",
    "        return self.decode_sequence(seq, i2o, o2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f99070c-20eb-448f-ad6a-a770624a558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = open('dataset.txt')\n",
    "\n",
    "dataset = dataset_file.readlines()\n",
    "dataset = [word.strip('\\n') for word in dataset]\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b43dd62-a890-497d-a56d-7888cb75b77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare parameters\n",
    "\n",
    "# fetch metadata\n",
    "metadata_file = open('metadata_ipa.txt')\n",
    "metadata = metadata_file.readlines()\n",
    "metadata = [line.strip('\\n') for line in metadata]\n",
    "metadata = [line.split('\\t') for line in metadata]\n",
    "metadata = [line[-1] for line in metadata]\n",
    "\n",
    "max_encoder_len = int(metadata[0])\n",
    "max_decoder_len = int(metadata[1])\n",
    "num_encoder_vocab = int(metadata[2])\n",
    "num_decoder_vocab = int(metadata[3])\n",
    "\n",
    "# fetch dictionaries\n",
    "e2i_file = open('ipa_e2i.pkl', 'rb')\n",
    "i2e_file = open('ipa_i2e.pkl', 'rb')\n",
    "d2i_file = open('ipa_d2i.pkl', 'rb')\n",
    "i2d_file = open('ipa_i2d.pkl', 'rb')\n",
    "\n",
    "e2i = pickle.load(e2i_file)\n",
    "i2e = pickle.load(i2e_file)\n",
    "d2i = pickle.load(d2i_file)\n",
    "i2d = pickle.load(i2d_file)\n",
    "\n",
    "e2i_file.close()\n",
    "i2e_file.close()\n",
    "d2i_file.close()\n",
    "i2d_file.close()\n",
    "metadata_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79cbe0ea-bb78-4a2c-a52f-12c5095caddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "syl2ipa = bi_model(max_encoder_len, max_decoder_len, num_encoder_vocab, num_decoder_vocab)\n",
    "syl2ipa.training_model.load_weights('syllable_translator_best_weights.h5')\n",
    "syl2ipa.build_inference_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94fc2b9b-df87-4bb7-a49e-946997d11288",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_ipa = open('training_data_ipa2ipa.txt', 'w+', encoding = 'utf-8')\n",
    "metadata_ipa_file = open('metadata_ipa2ipa.txt', 'w+')\n",
    "\n",
    "ipa_max_encoder_len = 0\n",
    "ipa_max_decoder_len = 0\n",
    "\n",
    "data_counter = 0\n",
    "\n",
    "ipa_encoder_vocab = []\n",
    "ipa_decoder_vocab = []\n",
    "\n",
    "def ipa_splitter(line):\n",
    "    global training_data_ipa\n",
    "    global ipa_max_encoder_len\n",
    "    global ipa_max_decoder_len\n",
    "    global ipa_encoder_vocab\n",
    "    global ipa_decoder_vocab\n",
    "    global data_counter\n",
    "    word = line.replace(';', '')\n",
    "    \n",
    "    actual_translation = ipa.convert(word)\n",
    "    if(not(actual_translation.endswith('*'))):\n",
    "        actual_translation = '<' + actual_translation + '>'\n",
    "        syllables = line.split(';')\n",
    "        attempted_translation = \"\"\n",
    "        for syl in syllables:\n",
    "            translation = seq2word(syl2ipa.translate(syl, e2i, i2d, d2i))\n",
    "            attempted_translation += translation\n",
    "        ipa_max_encoder_len = max(len(attempted_translation),ipa_max_encoder_len)\n",
    "        ipa_max_decoder_len = max(len(actual_translation),ipa_max_decoder_len)\n",
    "        \n",
    "        training_data_ipa.write(word + '\\t' + attempted_translation + '\\t' + actual_translation + '\\n')\n",
    "        data_counter += 1\n",
    "        for c in attempted_translation:\n",
    "            if c not in ipa_encoder_vocab:\n",
    "                ipa_encoder_vocab += [c]\n",
    "        for c in actual_translation:\n",
    "            if c not in ipa_decoder_vocab:\n",
    "                ipa_decoder_vocab += [c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "112cbb0d-04da-4189-8ad2-90b37a08550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "# creating syllable to ipa data\n",
    "for line in dataset[:2000]:\n",
    "    ipa_splitter(line)\n",
    "    print(data_counter, end='\\r')\n",
    "print(\"completed\")\n",
    "\n",
    "ipa_encoder_vocab = sorted(ipa_encoder_vocab)\n",
    "ipa_decoder_vocab = sorted(ipa_decoder_vocab)\n",
    "\n",
    "ipa_encoder_to_int = dict((a,i) for i,a in enumerate(ipa_encoder_vocab, 1))\n",
    "ipa_int_to_encoder = dict((i,a) for i,a in enumerate(ipa_encoder_vocab, 1))\n",
    "\n",
    "ipa_decoder_to_int = dict((a,i) for i,a in enumerate(ipa_decoder_vocab, 1))\n",
    "ipa_int_to_decoder = dict((i,a) for i,a in enumerate(ipa_decoder_vocab, 1))\n",
    "\n",
    "ipa_num_encoder_vocab = len(ipa_encoder_vocab) + 1\n",
    "ipa_num_decoder_vocab = len(ipa_decoder_vocab) + 1    \n",
    "\n",
    "training_data_ipa.close()\n",
    "metadata_ipa_file.write(\"ipa_max_encoder_len: \" + '\\t' + str(ipa_max_encoder_len) + '\\n')\n",
    "metadata_ipa_file.write(\"ipa_max_decoder_len: \" + '\\t' + str(ipa_max_decoder_len) + '\\n')\n",
    "metadata_ipa_file.write(\"ipa_num_encoder_vocab: \" + '\\t' + str(ipa_num_encoder_vocab) + '\\n')\n",
    "metadata_ipa_file.write(\"ipa_num_decoder_vocab: \" + '\\t' + str(ipa_num_decoder_vocab) + '\\n')\n",
    "metadata_ipa_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543d1d4-b438-4030-b9cb-d0b445671c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2i_file = open('ipa2ipa_e2i.pkl' , 'wb')\n",
    "i2e_file = open('ipa2ipa_i2e.pkl' , 'wb')\n",
    "d2i_file = open('ipa2ipa_d2i.pkl' , 'wb')\n",
    "i2d_file = open('ipa2ipa_i2d.pkl' , 'wb')\n",
    "\n",
    "pickle.dump(ipa_encoder_to_int, e2i_file)\n",
    "pickle.dump(ipa_int_to_encoder, i2e_file)\n",
    "pickle.dump(ipa_decoder_to_int, d2i_file)\n",
    "pickle.dump(ipa_int_to_decoder, i2d_file)\n",
    "\n",
    "e2i_file.close()\n",
    "i2e_file.close()\n",
    "d2i_file.close()\n",
    "i2d_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fd3aa9b-7772-46ec-8202-c31df1e128b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2word(array):\n",
    "    final_string = \"\"\n",
    "    for c in array:\n",
    "        final_string += c\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecef3a4a-ae67-45db-9e76-bca5f5f70823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:laptop_sketchbook] *",
   "language": "python",
   "name": "conda-env-laptop_sketchbook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
