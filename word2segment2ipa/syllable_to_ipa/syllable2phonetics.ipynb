{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95e0af89-567d-4be9-9518-60e2a19b8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Concatenate, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from BahdanauAttention import AttentionLayer\n",
    "import numpy as np\n",
    "import random\n",
    "import eng_to_ipa as ipa\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "454838f8-54dd-40e5-82a3-7d60a65bb6a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class bi_model:\n",
    "    def __init__(self, max_encoder_len, max_decoder_len, build_inference_model_encoder_vocab, num_decoder_vocab):\n",
    "        self.latent_dim = 256\n",
    "        self.embedding_dim = 200\n",
    "        self.max_encoder_len = max_encoder_len\n",
    "        self.max_decoder_len = max_decoder_len\n",
    "        self.num_encoder_vocab = num_encoder_vocab\n",
    "        self.num_decoder_vocab = num_decoder_vocab\n",
    "\n",
    "        self.build_encoder()\n",
    "        self.build_decoder()\n",
    "        self.training_model = Model([self.encoder_inputs, self.decoder_inputs], self.decoder_outputs) \n",
    "        \n",
    "    def build_encoder(self):\n",
    "        self.encoder_inputs = Input(shape=(self.max_encoder_len,)) \n",
    "        # Embedding layer- i am using 1024 output-dim for embedding you can try diff values 100,256,512,1000\n",
    "        self.enc_emb = Embedding(self.num_encoder_vocab, self.embedding_dim, trainable = True)(self.encoder_inputs)\n",
    "\n",
    "        # Bidirectional lstm layer\n",
    "        self.enc_lstm1 = Bidirectional(LSTM(self.latent_dim,return_sequences=True,return_state=True))\n",
    "        self.encoder_outputs1, self.forw_state_h, self.forw_state_c, self.back_state_h, self.back_state_c = self.enc_lstm1(self.enc_emb)\n",
    "\n",
    "        # Concatenate both h and c \n",
    "        self.final_enc_h = Concatenate()([self.forw_state_h,self.back_state_h])\n",
    "        self.final_enc_c = Concatenate()([self.forw_state_c,self.back_state_c])\n",
    "\n",
    "        # get Context vector\n",
    "        self.encoder_states =[self.final_enc_h, self.final_enc_c]\n",
    "    def build_decoder(self):\n",
    "        self.decoder_inputs = Input(shape=(None,)) \n",
    "\n",
    "        # decoder embedding with same number as encoder embedding\n",
    "        self.dec_emb_layer = Embedding(self.num_decoder_vocab, self.embedding_dim) \n",
    "        self.dec_emb = self.dec_emb_layer(self.decoder_inputs)   # apply this way because we need embedding layer for prediction \n",
    "\n",
    "        # In encoder we used Bidirectional so it's having two LSTM's so we have to take double units(256*2=512) for single decoder lstm\n",
    "        # LSTM using encoder's final states as initial state\n",
    "        self.decoder_lstm = LSTM(self.latent_dim*2, return_sequences=True, return_state=True) \n",
    "        self.decoder_outputs, _, _ = self.decoder_lstm(self.dec_emb, initial_state=self.encoder_states)\n",
    "\n",
    "        # Using Attention Layer\n",
    "        self.attention_layer = AttentionLayer()\n",
    "        self.attention_result, self.attention_weights = self.attention_layer([self.encoder_outputs1, self.decoder_outputs])\n",
    "\n",
    "        # Concat attention output and decoder LSTM output \n",
    "        self.decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([self.decoder_outputs, self.attention_result])\n",
    "\n",
    "        # Dense layer with softmax\n",
    "        self.decoder_dense = Dense(self.num_decoder_vocab, activation='softmax')\n",
    "        self.decoder_outputs = self.decoder_dense(self.decoder_concat_input)\n",
    "        \n",
    "    def compile(self):\n",
    "        self.training_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics = ['acc'])\n",
    "    \n",
    "    def fit(self, x_tr, y_tr_in, y_tr_out, x_test, y_test_in, y_test_out, ep, batch_size):\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "        ck = ModelCheckpoint(filepath='syllable_translator_best_weights.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "        Callbacks = [es, ck]\n",
    "        self.training_model.fit([x_tr,y_tr_in], y_tr_out, epochs = ep, callbacks=Callbacks, batch_size = batch_size, validation_data=(([x_test,y_test_in]), y_test_out))\n",
    "\n",
    "    def build_inference_model(self):\n",
    "        self.encoder_model_inference = Model(self.encoder_inputs, outputs = [self.encoder_outputs1, self.final_enc_h, self.final_enc_c])\n",
    "        \n",
    "        self.encoder_model_inference.save('s2p_encoder_inference_model.h5')\n",
    "        \n",
    "        # Decoder Inference\n",
    "        self.decoder_state_h = Input(shape=(self.latent_dim*2,)) # This numbers has to be same as units of lstm's on which model is trained\n",
    "        self.decoder_state_c = Input(shape=(self.latent_dim*2,))\n",
    "\n",
    "        # we need hidden state for attention layer\n",
    "        # 36 is maximum length if english sentence It has to same as input taken by attention layer can see in model plot\n",
    "        self.decoder_hidden_state_input = Input(shape=(self.max_encoder_len,self.latent_dim*2)) \n",
    "        # get decoder states\n",
    "        self.dec_states = [self.decoder_state_h, self.decoder_state_c]\n",
    "\n",
    "        # embedding layer \n",
    "        self.dec_emb2 = self.dec_emb_layer(self.decoder_inputs)\n",
    "        self.decoder_outputs2, self.state_h2, self.state_c2 = self.decoder_lstm(self.dec_emb2, initial_state=self.dec_states)\n",
    "\n",
    "        # Attention inference\n",
    "        self.attention_result_inf, self.attention_weights_inf = self.attention_layer([self.decoder_hidden_state_input, self.decoder_outputs2])\n",
    "        self.decoder_concat_input_inf = Concatenate(axis=-1, name='concat_layer')([self.decoder_outputs2, self.attention_result_inf])\n",
    "\n",
    "        self.dec_states2= [self.state_h2, self.state_c2]\n",
    "        self.decoder_outputs2 = self.decoder_dense(self.decoder_concat_input_inf)\n",
    "\n",
    "        # get decoder model\n",
    "        self.decoder_model_inference= Model(\n",
    "                            [self.decoder_inputs] + [self.decoder_hidden_state_input, self.decoder_state_h, self.decoder_state_c],\n",
    "                             [self.decoder_outputs2]+ self.dec_states2)\n",
    "        self.decoder_model_inference.save('s2p_decoder_inference_model.h5')\n",
    "        \n",
    "    def decode_sequence(self, input_seq, i2o, o2i):\n",
    "        e_out ,e_h, e_c = self.encoder_model_inference.predict(input_seq, verbose = 0)\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = o2i['<']\n",
    "\n",
    "        stop_condition = False\n",
    "        decoded_sentence = []\n",
    "\n",
    "        while not stop_condition:\n",
    "            (output_tokens, h, c) = self.decoder_model_inference.predict([target_seq] + [e_out, e_h, e_c], verbose = 0)\n",
    "\n",
    "            # Sample a token\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_token = i2o[sampled_token_index]   \n",
    "\n",
    "            if sampled_token != '>':\n",
    "                decoded_sentence += [sampled_token]\n",
    "\n",
    "            # Exit condition: either hit max length or find the stop word.\n",
    "            if (sampled_token == '>') or (len(decoded_sentence) >= self.max_decoder_len):\n",
    "                stop_condition = True\n",
    "\n",
    "            # Update the target sequence (of length 1)\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "            # Update internal states\n",
    "            (e_h, e_c) = (h, c)\n",
    "        return decoded_sentence\n",
    "    def word2seq(self, a2i, input_word):\n",
    "        final_seq = []\n",
    "        for c in input_word:\n",
    "            final_seq += [a2i[c]]\n",
    "        final_seq = pad_sequences([final_seq], maxlen=self.max_encoder_len, padding='post')[0]\n",
    "        return final_seq\n",
    "    \n",
    "    def translate(self, input_word, a2i, i2o, o2i):\n",
    "        seq = self.word2seq(a2i, input_word).reshape(1, self.max_encoder_len)\n",
    "        return self.decode_sequence(seq, i2o, o2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99c90ed7-9890-4c96-b984-9ebe905486f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare parameters\n",
    "\n",
    "# fetch metadata\n",
    "metadata_file = open('metadata_ipa.txt')\n",
    "metadata = metadata_file.readlines()\n",
    "metadata = [line.strip('\\n') for line in metadata]\n",
    "metadata = [line.split('\\t') for line in metadata]\n",
    "metadata = [line[-1] for line in metadata]\n",
    "\n",
    "max_encoder_len = int(metadata[0])\n",
    "max_decoder_len = int(metadata[1])\n",
    "num_encoder_vocab = int(metadata[2])\n",
    "num_decoder_vocab = int(metadata[3])\n",
    "\n",
    "# fetch dictionaries\n",
    "e2i_file = open('ipa_e2i.pkl', 'rb')\n",
    "i2e_file = open('ipa_i2e.pkl', 'rb')\n",
    "d2i_file = open('ipa_d2i.pkl', 'rb')\n",
    "i2d_file = open('ipa_i2d.pkl', 'rb')\n",
    "\n",
    "e2i = pickle.load(e2i_file)\n",
    "i2e = pickle.load(i2e_file)\n",
    "d2i = pickle.load(d2i_file)\n",
    "i2d = pickle.load(i2d_file)\n",
    "\n",
    "e2i_file.close()\n",
    "i2e_file.close()\n",
    "d2i_file.close()\n",
    "i2d_file.close()\n",
    "metadata_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6be69d87-15be-4e64-b9d5-0a41beb96349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch training data\n",
    "training_data_file = open('training_data_ipa.txt', encoding = 'UTF-8')\n",
    "raw_data = training_data_file.readlines()\n",
    "raw_data = [line.strip('\\n') for line in raw_data]\n",
    "raw_split_data = [line.split('\\t') for line in raw_data]\n",
    "syllable_list = [pair[0] for pair in raw_split_data]\n",
    "ipa_list = [pair[1] for pair in raw_split_data]\n",
    "\n",
    "syllable_list = np.array(syllable_list).reshape((1,len(syllable_list)))\n",
    "ipa_list = np.array(ipa_list).reshape((1,len(ipa_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56680d65-f9fd-443a-9e66-727f0937127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x_train data\n",
    "x_tr = []\n",
    "\n",
    "for syl in syllable_list[0]:\n",
    "    int_seq = []\n",
    "    for c in syl:\n",
    "        int_seq += [e2i[c]]\n",
    "    x_tr += [int_seq]\n",
    "x_tr = pad_sequences(x_tr, maxlen=max_encoder_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9743697-3936-4d0c-8527-08383b8f5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create y_train data\n",
    "y_tr = []\n",
    "\n",
    "for seq in ipa_list[0]:\n",
    "    int_seq = []\n",
    "    for c in seq:\n",
    "        int_seq += [d2i[c]]\n",
    "    y_tr += [int_seq]\n",
    "y_tr = pad_sequences(y_tr, maxlen=max_decoder_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e36984e5-0ccf-49bf-a43b-e8d3b7c985b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation sets\n",
    "# x_novel = x_tr[5000:]\n",
    "# y_novel = y_tr[5000:]\n",
    "\n",
    "# x_tr = x_tr[:5000]\n",
    "# y_tr = y_tr[:5000]\n",
    "\n",
    "split_index = int(len(x_tr) * .8)\n",
    "\n",
    "y_test = y_tr[split_index:]\n",
    "y_test_in = y_test[:, :-1]\n",
    "y_test_out = y_test[:, 1:]\n",
    "\n",
    "y_tr = y_tr[:split_index]\n",
    "y_tr_in = y_tr[:, :-1]\n",
    "y_tr_out = y_tr[:, 1:]\n",
    "\n",
    "x_test = x_tr[split_index:]\n",
    "x_tr = x_tr[:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bf9d0fa-bed8-4903-8e70-911181f179ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914\n"
     ]
    }
   ],
   "source": [
    "print(len(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01696e64-d23d-45ae-950c-af5454e5f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_translator = bi_model(max_encoder_len, max_decoder_len, num_encoder_vocab, num_decoder_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b61b4544-150e-4efb-8c8d-71bee55074e6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 47s 1s/step - loss: 1.2553 - acc: 0.6921 - val_loss: 1.0541 - val_acc: 0.7134\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71336, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 36s 1s/step - loss: 0.9181 - acc: 0.7619 - val_loss: 0.9153 - val_acc: 0.7799\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71336 to 0.77988, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 36s 1s/step - loss: 0.7923 - acc: 0.8013 - val_loss: 0.9142 - val_acc: 0.7503\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.77988\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.6195 - acc: 0.8345 - val_loss: 0.5668 - val_acc: 0.8470\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.77988 to 0.84704, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 37s 1s/step - loss: 0.4172 - acc: 0.8867 - val_loss: 0.4173 - val_acc: 0.8791\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.84704 to 0.87909, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 36s 1s/step - loss: 0.2877 - acc: 0.9201 - val_loss: 0.2950 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.87909 to 0.91081, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 33s 1s/step - loss: 0.2091 - acc: 0.9397 - val_loss: 0.3114 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91081\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 33s 1s/step - loss: 0.1634 - acc: 0.9522 - val_loss: 0.1744 - val_acc: 0.9537\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91081 to 0.95365, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 35s 1s/step - loss: 0.1264 - acc: 0.9626 - val_loss: 0.2594 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95365\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 33s 1s/step - loss: 0.1090 - acc: 0.9683 - val_loss: 0.1500 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.95365 to 0.95870, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 34s 1s/step - loss: 0.0955 - acc: 0.9728 - val_loss: 0.1235 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.95870 to 0.96616, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 34s 1s/step - loss: 0.0757 - acc: 0.9785 - val_loss: 0.1141 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.96616 to 0.96916, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 33s 1s/step - loss: 0.0705 - acc: 0.9800 - val_loss: 0.1019 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.96916 to 0.97248, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 34s 1s/step - loss: 0.0596 - acc: 0.9831 - val_loss: 0.0989 - val_acc: 0.9733\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.97248 to 0.97331, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 33s 1s/step - loss: 0.0509 - acc: 0.9860 - val_loss: 0.1001 - val_acc: 0.9734\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.97331 to 0.97344, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 32s 1s/step - loss: 0.0461 - acc: 0.9873 - val_loss: 0.1004 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.97344 to 0.97363, saving model to syllable_translator_best_weights.h5\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "syllable_translator.compile()\n",
    "syllable_translator.fit(x_tr, y_tr_in, y_tr_out, x_test, y_test_in, y_test_out, ep=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d296a1ad-9d00-4f15-9c64-1c51ee4dad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# resume training\n",
    "# segmenter.compile()\n",
    "syllable_translator.training_model.load_weights('syllable_translator_best_weights.h5')\n",
    "# segmenter.fit(x_tr, y_tr_in, y_tr_out, x_test, y_test_in, y_test_out, ep=50, batch_size=128)\n",
    "syllable_translator.build_inference_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89149535-7fd6-43be-8404-cb1d9d7dd478",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  sus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Given syllable is in the original training dataset\n",
      "səs\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  ses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sɛs\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  ing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Given syllable is in the original training dataset\n",
      "ɪŋ\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  kint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nɪnt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  nint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nɪnt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  grint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grɪnt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  ung\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "əŋ\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  aigh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eɪg\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  aight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eɪt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  ight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aɪt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  ment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mɛnt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  pin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Given syllable is in the original training dataset\n",
      "pɪn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a syllable to be translated, or 'quit' to exit:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "word = \"\"\n",
    "while(word != 'quit'):\n",
    "    word = input(\"Enter a syllable to be translated, or 'quit' to exit: \")\n",
    "    if(word == 'quit'):\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    if(in_data(word, x_tr)):\n",
    "       print(\"Warning: Given syllable is in the original training dataset\")\n",
    "    print(seq2word(syllable_translator.translate(word, e2i, i2d, d2i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a37c468-2871-4beb-b8b8-a1b625ef8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_data(word, data):\n",
    "    if [word] in syllable_list[0]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df323d95-7ba1-4075-b828-ad8a3fadc5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2word(array):\n",
    "    final_string = \"\"\n",
    "    for c in array:\n",
    "        final_string += c\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71259399-9c0d-423a-a8e5-a7968dfa97cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:laptop_sketchbook] *",
   "language": "python",
   "name": "conda-env-laptop_sketchbook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
